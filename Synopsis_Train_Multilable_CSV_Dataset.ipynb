{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Synopsis Train Multilable CSV Dataset",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtrYGnFrZH9-",
        "colab_type": "text"
      },
      "source": [
        "[link text](https://)Synopsis Multi Class, Multi Label transfer learning training script using a sparsely labeled data set - labels values correspond to positive that concept present (1), positive that the concept is not present (0) and uncertain if the concept is present at all (-1)\n",
        "\n",
        "We use Mobilenet V2 with no top as our feature extractor and are experimenting with various optimizer and losses to work with missing labels.\n",
        "\n",
        "This notebook is part of the Synopsis project (see http://github.com/synopsis) and based heavily off of the Tensorflow custom data loading and transfer learning ipynb examples.\n",
        "\n",
        "See these resources for info:\n",
        "\n",
        "* https://stats.stackexchange.com/questions/207794/what-loss-function-for-multi-class-multi-label-classification-tasks-in-neural-n\n",
        "\n",
        "* https://machinelearningmastery.com/how-to-choose-loss-functions-when-training-deep-learning-neural-networks/\n",
        "\n",
        "* https://github.com/keras-team/keras/issues/10371"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v72jzd2UU_Z",
        "colab_type": "text"
      },
      "source": [
        "# GCS Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tARUJzuLVA_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Configure GCS\n",
        "project_id = 'dev-sphere-240918'\n",
        "bucket_name = 'synopsis_cinemanet'\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SD7S8F8MYQh8",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup / Dependencies\n",
        "\n",
        "Note we require TF 1.15 for some of our (current) training set up, which requires us to install some dependencies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZRaBj51RvEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall -y tensorflow tensorflow-estimator tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0_9wy8aIW0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add NVIDIA package repositories\n",
        "!wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "!sudo yes | dpkg -i cuda-repo-ubuntu1804_10.0.130-1_amd64.deb\n",
        "!sudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub\n",
        "!sudo apt-get update\n",
        "!wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64/nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "!sudo yes | dpkg -i nvidia-machine-learning-repo-ubuntu1804_1.0.0-1_amd64.deb\n",
        "!sudo apt-get update\n",
        "\n",
        "# Install NVIDIA driver\n",
        "# !sudo apt-get install --no-install-recommends nvidia-driver-418\n",
        "# !sudo apt-get -y installnvidia-driver-418\n",
        "# Reboot. Check that GPUs are visible using the command: nvidia-smi\n",
        "\n",
        "# Install development and runtime libraries (~4GB)\n",
        "!sudo apt-get install -y --allow-change-held-packages --no-install-recommends \\\n",
        "    cuda-10-0 \\\n",
        "    libcudnn7=7.6.2.24-1+cuda10.0  \\\n",
        "    libcudnn7-dev=7.6.2.24-1+cuda10.0\n",
        "\n",
        "\n",
        "# Install TensorRT. Requires that libcudnn7 is installed above.\n",
        "!sudo apt-get install -y --allow-change-held-packages -y --no-install-recommends libnvinfer5=5.1.5-1+cuda10.0 \\\n",
        "    libnvinfer-dev=5.1.5-1+cuda10.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgET5jsaLIpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!sudo rm /usr/local/cuda\n",
        "!sudo ln -s /usr/local/cuda-10.0 /usr/local/cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er3MidcSnsBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -al /usr/local/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjaXGTrao0F6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our TF PB to CoreML converter\n",
        "!pip install coremltools --no-dependencies\n",
        "!pip install tfcoreml --no-dependencies\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4jw7VhVK8gr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up dependencies:\n",
        "!pip install tensorflow-gpu==1.14"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPQHx8pnYHBp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Data Set and Training Below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YMN-ykwUyFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load tensorflow\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
        "\n",
        "tf.test.gpu_device_name()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PrWthWryUyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# some defs:\n",
        "IMG_SIZE = 224\n",
        "MODEL_TYPE = \"MOBILENET\" # could also be \"NASNET\"\n",
        "DATA_ROOT = \"/tmp/Synopsis_Model_All_Concepts/\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wCV4WQfVg_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# copy our data set\n",
        "!gsutil -m cp -r gs://{bucket_name}/Synopsis_Model_All_Concepts.zip /tmp/\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQrvylCs0auk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Unzip our dataset to /tmp/\n",
        "!unzip -qq /tmp/Synopsis_Model_All_Concepts.zip -d /tmp/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl3mCz9aY9Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_label_files = [\n",
        "                  \"shot_lighting.csv\",\n",
        "                  \"color_saturation.csv\",\n",
        "                  \"color_key.csv\",\n",
        "                  \"color_theory.csv\",\n",
        "                  \"color_tones.csv\",\n",
        "                  \"shot_angle.csv\",\n",
        "                  \"shot_focus.csv\",\n",
        "                  \"shot_framing.csv\",\n",
        "                  \"shot_level.csv\",\n",
        "                  \"shot_location.csv\",\n",
        "                  \"shot_subject.csv\",\n",
        "                  \"shot_timeofday.csv\",\n",
        "                  \"shot_type.csv\",\n",
        "                  \"texture.csv\",\n",
        "                   ]\n",
        "# masked loss is an attempt at having 'unknowns' for some concepts where data isnt exhaustively labeled\n",
        "# for example, an image thats a city exterior may contain concepts like sidewalk / street / store as well, but arent marked as such\n",
        "# since wedont have a huge labelling force\n",
        "\n",
        "# its unclear if this is a win. Its likely questionable but we dont have exhaustively labeled data just yet... \n",
        "\n",
        "labels_using_masked_loss = [\n",
        "                  True,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,\n",
        "                  False,  \n",
        "                  False,\n",
        "                   ]\n",
        "\n",
        "# TODO: Refactor this to be a dictionary of label csv, loss function, and augmentation functions\n",
        "# assign agumentations for each data set. Not all are appropriate.\n",
        "# ... "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXIhKPBCW5gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download our label file\n",
        "for label in all_label_files:\n",
        "  label_file = DATA_ROOT + label\n",
        "  !gsutil -m cp -r gs://{bucket_name}/Synopsis_Model_All_Concepts/{label} {label_file}\n",
        "  # verify our MD5 so we know we are on an expected label file:\n",
        "  !md5sum {label_file}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TY0YCZLRXHK",
        "colab_type": "text"
      },
      "source": [
        "DATA SET HELPER METHODS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqT8dtd9zV_c",
        "colab_type": "text"
      },
      "source": [
        "DATA AUGMENTATION HELPERS\n",
        "\n",
        "See https://www.wouterbulten.nl/blog/tech/data-augmentation-using-tensorflow-data-dataset/\n",
        "\n",
        "To be implemented\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXAUWP1NzVl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_rotate(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Rotation augmentation\n",
        "\n",
        "    Args:\n",
        "        x: Image\n",
        "\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "\n",
        "    # Rotate 0, 90, 180, 270 degrees\n",
        "    return tf.image.rot90(x, tf.random_uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjFTezhiznVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_flip_horizontal(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Flip augmentation\n",
        "\n",
        "    Args:\n",
        "        x: Image to flip\n",
        "\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "    x = tf.image.random_flip_left_right(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLEAPSSzz5fp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_color(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Color augmentation\n",
        "\n",
        "    Args:\n",
        "        x: Image\n",
        "\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "    x = tf.image.random_hue(x, 0.08)\n",
        "    x = tf.image.random_saturation(x, 0.6, 1.6)\n",
        "    x = tf.image.random_brightness(x, 0.05)\n",
        "    x = tf.image.random_contrast(x, 0.7, 1.3)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3AlEVoJ0LiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_zoom(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Zoom augmentation\n",
        "\n",
        "    Args:\n",
        "        x: Image\n",
        "\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n",
        "    scales = list(np.arange(0.8, 1.0, 0.01))\n",
        "    boxes = np.zeros((len(scales), 4))\n",
        "\n",
        "    for i, scale in enumerate(scales):\n",
        "        x1 = y1 = 0.5 - (0.5 * scale)\n",
        "        x2 = y2 = 0.5 + (0.5 * scale)\n",
        "        boxes[i] = [x1, y1, x2, y2]\n",
        "\n",
        "    def random_crop(img):\n",
        "        # Create different crops for an image\n",
        "        crops = tf.image.crop_and_resize([img], boxes=boxes, box_ind=np.zeros(len(scales)), crop_size=(32, 32))\n",
        "        # Return a random crop\n",
        "        return crops[tf.random_uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
        "\n",
        "\n",
        "    choice = tf.random_uniform(shape=[], minval=0., maxval=1., dtype=tf.float32)\n",
        "\n",
        "    # Only apply cropping 50% of the time\n",
        "    return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UvQIXixzsWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_flip_vertical(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Flip augmentation\n",
        "\n",
        "    Args:\n",
        "        x: Image to flip\n",
        "\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "    x = tf.image.random_flip_up_down(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shh7ezG8WPuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dataset(file_path,  BATCH_SIZE, NUM_EPOCHS, COLUMN_NAMES, **kwargs,):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=BATCH_SIZE, \n",
        "      na_value=\"?\",\n",
        "      num_epochs=NUM_EPOCHS,\n",
        "      column_names=COLUMN_NAMES,\n",
        "      ignore_errors=True, \n",
        "      shuffle=True, #TEMPORARY\n",
        "      **kwargs)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q-2HX8hZ1OL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we need to split out our data set to matching file paths and the labels as a sparse vector for each label,\n",
        "# containing 1, 0, -1 values for label concept present, label concept not present, dont know if present \n",
        "\n",
        "# for example, a CSV row like \n",
        "# color_key_blue/1-5.jpg,1,0,0,0,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1\n",
        "# should return:\n",
        "# * a tensor containing a path like data_root + /color_key_blue/1-5.jpg, \n",
        "# * a tensor of values [1,0,0,0, -1 etc]\n",
        "\n",
        "# a function that returns a path, ordered dict of only the \n",
        "\n",
        "import tensorflow.python.util\n",
        "def split_csv_to_path_and_labels(csv_row_Dict):\n",
        "  # print(\"Calling split_csv_to_path_and_label\")\n",
        " \n",
        "  filepath = csv_row_Dict.pop('filepath')\n",
        "  data_root_tensor = tf.constant(DATA_ROOT)\n",
        "  \n",
        "  filepath = tf.strings.join([data_root_tensor, filepath], separator='')\n",
        "  \n",
        "  #make a new tensor with the values of the LABEL_NAMES keys but packed into a 0, len(LABEL_NAMES) array\n",
        "  labels = tf.stack(list(csv_row_Dict.values()), axis=1)\n",
        "\n",
        "  return filepath, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYSodNJt5D_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_image(image, augmentations):\n",
        "  if augmentations != None:\n",
        "    # do augmentations\n",
        "    for agumentation in augmentations:\n",
        "      image = agumentation(image)\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HmUiZJNU73vA",
        "colab": {}
      },
      "source": [
        " # some image loading and normalization code:\n",
        " def preprocess_image(image, augmentations):\n",
        "  image = tf.image.decode_jpeg(image, channels=3, dct_method=\"INTEGER_ACCURATE\")\n",
        "  image = tf.cast(image, tf.float32)\n",
        "\n",
        "  # augment on our full size image if we have any\n",
        "  # image = augment_image(image, None)\n",
        "\n",
        "  image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE], method='bilinear', preserve_aspect_ratio=False)\n",
        "\n",
        "  image /= 255.0  # normalize to [0,1] range\n",
        "  \n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "einETrJnO-em",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def load_and_preprocess_single_image_from_tensor(path,augmentations = None):\n",
        "   image = tf.io.read_file(path)\n",
        "   if image == None:\n",
        "    print(\"Unable to load image at path:\" + path )\n",
        "   return preprocess_image(image, augmentations)\n",
        "    \n",
        "# this method uses function map\n",
        "def load_and_preprocess_image_batch(batch_of_paths, batch_of_labels):\n",
        "  batch_of_images = tf.map_fn(load_and_preprocess_single_image_from_tensor, batch_of_paths, dtype=tf.float32)\n",
        "  return batch_of_images, batch_of_labels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgQMy4_8SDCr",
        "colab_type": "text"
      },
      "source": [
        "TRAINING HELPER METHODS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpGZlQkswmsu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add a custom loss function to manage our multi label, multi class -1 (unknown) values\n",
        "#https://github.com/keras-team/keras/issues/3893\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "MASK_VALUE = -1\n",
        "\n",
        "def build_masked_loss(loss_function, mask_value=MASK_VALUE):\n",
        "    \"\"\"Builds a loss function that masks based on targets\n",
        "\n",
        "    Args:\n",
        "        loss_function: The loss function to mask\n",
        "        mask_value: The value to mask in the targets\n",
        "\n",
        "    Returns:\n",
        "        function: a loss function that acts like loss_function with masked inputs\n",
        "    \"\"\"\n",
        "\n",
        "    def masked_loss_function(y_true, y_pred):\n",
        "        mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
        "        return loss_function(y_true * mask, y_pred * mask)\n",
        "\n",
        "    return masked_loss_function\n",
        "\n",
        "def masked_accuracy(y_true, y_pred):\n",
        "    \n",
        "    dtype = K.floatx()\n",
        "    total = K.sum(K.cast(K.not_equal(y_true, MASK_VALUE), dtype) )\n",
        "    correct = K.sum(K.cast(K.equal(y_true, K.round(y_pred)), dtype) )\n",
        "    \n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSo51FrVIrRr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alternatively:\n",
        "# taken from https://www.dlology.com/blog/how-to-multi-task-learning-with-missing-labels-in-keras/\n",
        "def masked_loss_function(y_true, y_pred):\n",
        "    mask = K.cast(K.not_equal(y_true, MASK_VALUE), K.floatx())\n",
        "    return K.binary_crossentropy(y_true * mask, y_pred * mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfMHJJlTwI0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alternatively:\n",
        "# from https://stats.stackexchange.com/questions/207794/what-loss-function-for-multi-class-multi-label-classification-tasks-in-neural-n\n",
        "def abs_KL_div(y_true, y_pred):\n",
        "    y_true = K.clip(y_true, K.epsilon(), None)\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), None)\n",
        "    return K.sum( K.abs( (y_true- y_pred) * (K.log(y_true / y_pred))), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3khxrPXDnjvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alternatively:\n",
        "#  https://github.com/keras-team/keras/issues/11749#issuecomment-498709628 :\n",
        "def custom_sparse_categorical_accuracy(y_true, y_pred):\n",
        "    return K.cast(K.equal(K.max(y_true, axis=-1),\n",
        "                          K.cast(K.argmax(y_pred, axis=-1), K.floatx())),K.floatx())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TINup7NvHOHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set up our model, MNASNet or MobileNet\n",
        "from keras.metrics import categorical_accuracy\n",
        "\n",
        "def build_model(LABEL_NAMES, use_masked_loss = True):\n",
        "  # base_model = tf.keras.applications.NASNetMobile(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "  #                                                include_top=False,\n",
        "  #                                                weights='imagenet')\n",
        "  base_model = tf.keras.applications.MobileNetV2(input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "                                                include_top=False,\n",
        "                                                weights='imagenet')\n",
        "\n",
        "  base_model.summary()\n",
        "\n",
        "  base_model.trainable = False\n",
        "\n",
        "  # Let's take a look to see how many layers are in the base model\n",
        "  print(\"Number of layers in the base model: \", len(base_model.layers))\n",
        "\n",
        "  # Fine tune from this layer onwards\n",
        "  #fine_tune_at = 600\n",
        "\n",
        "  # Freeze all the layers before the `fine_tune_at` layer\n",
        "  #for layer in base_model.layers[:fine_tune_at]:\n",
        "  #  layer.trainable =  False\n",
        "\n",
        "  #base_model.summary()\n",
        "  num_labels = len(LABEL_NAMES)\n",
        "  print(\"Number of Labels in model \" + str(num_labels))\n",
        "\n",
        "  output = tf.keras.layers.Dense(num_labels, activation = 'sigmoid', name=\"cinemanet_output\")\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    output])\n",
        "\n",
        "  print(model.input.op.name)\n",
        "  print(model.input)\n",
        "\n",
        "  print(model.output.op.name)\n",
        "  print(model.output)\n",
        "\n",
        "  loss = 'binary_crossentropy'\n",
        "  metrics = ['accuracy','categorical_accuracy']\n",
        "  if use_masked_loss:\n",
        "    loss = build_masked_loss(K.binary_crossentropy)\n",
        "    metrics = [masked_accuracy, 'accuracy','categorical_accuracy']\n",
        "\n",
        "# compile our model\n",
        "  optimizer = tf.train.AdamOptimizer()\n",
        "  model.compile(optimizer=optimizer,\n",
        "                # loss=build_masked_loss(K.binary_crossentropy),\n",
        "                loss = loss,\n",
        "                metrics = metrics)\n",
        "\n",
        "                # loss=build_masked_loss(K.categorical_crossentropy),\n",
        "                \n",
        "                # TODO: Figure out:\n",
        "                #loss= tf.compat.v1.nn.sigmoid_cross_entropy_with_logits(labels=labels_tensor, logits=label_batch[0]),                           \n",
        "                # TODO: Figure out:\n",
        "                #loss = tf.keras.losses.sparse_categorical_crossentropy,\n",
        "                \n",
        "                # https://github.com/keras-team/keras/issues/11749\n",
        "                # see categorical_accuracy vs accuracy \n",
        "\n",
        "                \n",
        "  #               metrics=[\"accuracy\"]\n",
        "                # metrics=[\"sparse_categorical_accuracy\"])\n",
        "  #               metrics=[custom_sparse_categorical_accuracy])\n",
        "\n",
        "#flag to run on tpu \n",
        "  # tpu = False\n",
        "  # if tpu:\n",
        "  #   tpu_grpc_url = \"grpc://\"+os.environ[\"COLAB_TPU_ADDR\"]\n",
        "    \n",
        "  #   #connect the TPU cluster using the address \n",
        "  #   tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu_grpc_url)\n",
        "    \n",
        "  #   #run the model on different clusters \n",
        "  #   strategy = keras_support.TPUDistributionStrategy(tpu_cluster_resolver)\n",
        "    \n",
        "  #   #convert the model to run on tpu \n",
        "  #   model = tf.contrib.tpu.keras_to_tpu_model(model, strategy=strategy)\n",
        "\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtv_QC1jHgU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# image data for MNAS / Mobilenet needs to be -1, 1\n",
        "def change_range(image,label):\n",
        "  return 2.0 * image -1.0, label\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7a-37SGOUGy3",
        "colab_type": "text"
      },
      "source": [
        "EXPORT HELPER CODE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw3pfa8szd5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def keras_model_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return \"/tmp/\" + now + \"/\" + model_name_without_extension + '.h5'\n",
        "\n",
        "def keras_json_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return \"/tmp/\" + now + \"/\" + model_name_without_extension + '.json'\n",
        "\n",
        "def keras_weights_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return \"/tmp/\" + now + \"/\" + model_name_without_extension + '-weights.h5'\n",
        "\n",
        "def pb_model_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return (\"/tmp/\" + now + \"/\",   model_name_without_extension + '.pb')\n",
        "\n",
        "def pb_classifier_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return \"/tmp/\" + now + \"/\" + model_name_without_extension + '-classifier.pb'\n",
        "\n",
        "def pb_feature_extractor_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return \"/tmp/\" + now + \"/\" + model_name_without_extension + '-feature-extractor.pb'\n",
        "\n",
        "def coreml_model_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return \"/tmp/\" + now + \"/\" + model_name_without_extension + '.mlmodel'\n",
        "\n",
        "def coreml_classifier_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return \"/tmp/\" + now + \"/\" + model_name_without_extension + '-classifier.mlmodel'\n",
        "\n",
        "def coreml_feature_extractor_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return \"/tmp/\" + now + \"/\" + model_name_without_extension + '-feature-extractor.mlmodel'\n",
        "\n",
        "def labels_model_path(date, model_name_without_extension):\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "  return \"/tmp/\" + now + \"/\" + model_name_without_extension + '_labels.txt'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9Aa79024HFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def export_model_keras(model, model_name_without_extension, date):\n",
        "  # save as a 'Saved Model'\n",
        "  #tf.keras.experimental.export_saved_model(model, model_path+\"_saved_model\")\n",
        "\n",
        "  # WHEN USING FREEZE GRAPH  IN TF 1.14 ON SAVED MODEL:\n",
        "  # AssertionError: cinemanet_output/Identity is not in graph\n",
        "\n",
        "  # Save as a Keras H5 (two methods)\n",
        "  # model.save(model_path + '.h5')\n",
        "  tf.keras.models.save_model(model, keras_model_path(date, model_name_without_extension) , overwrite=True, save_format=\"h5\")\n",
        "\n",
        "  # TF 1.1.4 / TF.KERAS CANNOT LOAD THE FINAL OUTPUT FROM THE h5 - This is Bug #28668\n",
        "  # TF 2.0 CAN LOAD THE TF.KERAS h5 WITH THE cinemanet_output/Identity node\n",
        "  # HOWEVER TF 2.0 CANNOT RUN FREEZE GRAPH OR FREEZE SESSION DUE TO LACK OF SESSION / GRAPH API.\n",
        "  # TF SAVED MODEL HOWEVER \"WORKS\" BUT THE RESULTING PROTOCOL BUFFER IS SOME WEIRD \"I DID NOT ASK FOR THIS\"\n",
        "  # TF SERVING PB VERSION WITH NO OUTPUTS WHOSE GRAPH LOOKS TOTALLY DIFFERENT THAN MY INPUT\n",
        "  # SECONDLY THIS SAVED MODEL FILE DOES NOT CONTAIN cinemanet_output/Identity AND NOR \n",
        "  # DOES ANY OTHER EXTERNAL TOOL HAVE THE ABILITY TO CONVER THIS TO A \"I ASKED FOR THIS\" PB\n",
        "  # ALSO TF 1.14 WHICHD DOES SUPPORT TF SAVED MODEL FORMAT CANNOT CONVERT THIS TO A VALID OUTPUT\n",
        "  # IT ERRORS WITH \n",
        "  # SURPRISE\n",
        "  # AssertionError: cinemanet_output/Identity is not in graph\n",
        "\n",
        "\n",
        "  # Save as a Keras JSON / JSON Weights\n",
        "  model_json = model.to_json()\n",
        "  with open( keras_json_path(date, model_name_without_extension), \"w\") as json_file:\n",
        "      json_file.write(model_json)\n",
        "  model.save_weights(keras_weights_path(date, model_name_without_extension))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gWi6th10Hmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define our freeze graph method\n",
        "def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):\n",
        "    \"\"\"\n",
        "    Freezes the state of a session into a pruned computation graph.\n",
        "    Creates a new computation graph where variable nodes are replaced by\n",
        "    constants taking their current value in the session. The new graph will be\n",
        "    pruned so subgraphs that are not necessary to compute the requested\n",
        "    outputs are removed.\n",
        "    @param session The TensorFlow session to be frozen.\n",
        "    @param keep_var_names A list of variable names that should not be frozen,\n",
        "                          or None to freeze all the variables in the graph.\n",
        "    @param output_names Names of the relevant graph outputs.\n",
        "    @param clear_devices Remove the device directives from the graph for better portability.\n",
        "    @return The frozen graph definition.\n",
        "    \"\"\"\n",
        "    from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
        "    graph = session.graph\n",
        "    with graph.as_default():\n",
        "        freeze_var_names = list(set(v.op.name for v in tf.global_variables()).difference(keep_var_names or []))\n",
        "        output_names = output_names or []\n",
        "        output_names += [v.op.name for v in tf.global_variables()]\n",
        "        # Graph -> GraphDef ProtoBuf\n",
        "        input_graph_def = graph.as_graph_def()\n",
        "        if clear_devices:\n",
        "            for node in input_graph_def.node:\n",
        "                node.device = \"\"\n",
        "        frozen_graph = convert_variables_to_constants(session, input_graph_def,\n",
        "                                                      output_names, freeze_var_names)\n",
        "        return frozen_graph\n",
        "\n",
        "\n",
        "def export_model_pb(model, model_name_without_extension, date):\n",
        "  tf.reset_default_graph()\n",
        "  K.set_learning_phase(0)\n",
        "\n",
        "  restored_model = tf.keras.models.load_model( keras_model_path(date, model_name_without_extension), compile=True)\n",
        "\n",
        "  # print(restored_model.input.op.name)\n",
        "  # print(restored_model.input)\n",
        "\n",
        "  # print(restored_model.output.op.name)\n",
        "  # print(restored_model.output)\n",
        "  # restored_model.summary()\n",
        "\n",
        "  frozen_graph = freeze_session(K.get_session(),\n",
        "                              output_names=[out.op.name for out in restored_model.outputs])\n",
        "  #save our PB to temp\n",
        "  model_location_and_name_tuple = pb_model_path(date, model_name_without_extension)\n",
        "  tf.train.write_graph(frozen_graph, model_location_and_name_tuple[0], model_location_and_name_tuple[1], as_text=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RXXeLycXMG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def segment_model_pb(model_name_without_extension, date):\n",
        "    # segment the above PB file to 2 graphs, feature extractor and classifier\n",
        "  # Load the TF graph definition\n",
        "  #tf_model_path = \"/tmp/\" + model_name_without_extension+\".pb\"\n",
        "  tf_model_path_tuple = pb_model_path(date, model_name_without_extension)\n",
        "  tf_model_path = tf_model_path_tuple[0] + tf_model_path_tuple[1]\n",
        "\n",
        "  with open(tf_model_path, 'rb') as f:\n",
        "      serialized = f.read()\n",
        "\n",
        "  tf.reset_default_graph()\n",
        "  original_gdef = tf.GraphDef()\n",
        "  original_gdef.ParseFromString(serialized)\n",
        "\n",
        "  from tensorflow.python.tools import strip_unused_lib\n",
        "  from tensorflow.python.framework import dtypes\n",
        "  from tensorflow.python.platform import gfile\n",
        "\n",
        "  input_extractor_node_names = ['mobilenetv2_1.00_224_input']\n",
        "  output_extractor_node_names = ['global_average_pooling2d/Mean']\n",
        "\n",
        "  input_classifier_nodes_names = ['global_average_pooling2d/Mean']\n",
        "  output_classifier_node_names = ['cinemanet_output/Sigmoid']\n",
        "\n",
        "  extractor_gdef = strip_unused_lib.strip_unused(\n",
        "          input_graph_def = original_gdef,\n",
        "          input_node_names = input_extractor_node_names,\n",
        "          output_node_names = output_extractor_node_names,\n",
        "          placeholder_type_enum = dtypes.float32.as_datatype_enum)\n",
        "\n",
        "  classifier_gdef = strip_unused_lib.strip_unused(\n",
        "          input_graph_def = original_gdef,\n",
        "          input_node_names = input_classifier_nodes_names,\n",
        "          output_node_names = output_classifier_node_names,\n",
        "          placeholder_type_enum = dtypes.float32.as_datatype_enum)\n",
        "\n",
        "\n",
        "  # Save it to an output file\n",
        "  extractor_graph_file  = pb_feature_extractor_path(date, model_name_without_extension)\n",
        "  classifier_graph_file  = pb_classifier_path(date, model_name_without_extension) \n",
        "\n",
        "  with gfile.GFile(extractor_graph_file, \"wb\") as f:\n",
        "      f.write(extractor_gdef.SerializeToString())\n",
        "\n",
        "  with gfile.GFile(classifier_graph_file, \"wb\") as f:\n",
        "      f.write(classifier_gdef.SerializeToString())    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIjUm-nDyqv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_segment_to_coreml(model_name_without_extension, label_names, date):\n",
        "  #convert our PB to an ML Model\n",
        "  import tfcoreml as tf_converter\n",
        "\n",
        "  extractor_graph_file  = pb_feature_extractor_path(date, model_name_without_extension)\n",
        "  classifier_graph_file  = pb_classifier_path(date, model_name_without_extension) \n",
        "\n",
        "  feature_extractor_name = coreml_feature_extractor_path(date, model_name_without_extension)\n",
        "  classifier_name = coreml_classifier_path(date, model_name_without_extension) \n",
        "\n",
        "  # output our feature extractor\n",
        "  # input images -> 1056 element vector:\n",
        "  tf_converter.convert(tf_model_path = extractor_graph_file,\n",
        "                      mlmodel_path = feature_extractor_name,\n",
        "                      output_feature_names = ['global_average_pooling2d/Mean:0'],\n",
        "                      input_name_shape_dict = {'mobilenetv2_1.00_224_input:0' : [1,IMG_SIZE,IMG_SIZE,3]},\n",
        "                      image_input_names ='mobilenetv2_1.00_224_input:0',\n",
        "                      red_bias=-1,\n",
        "                      green_bias=-1,\n",
        "                      blue_bias=-1,\n",
        "                      image_scale=2.0/255.0,\n",
        "                      is_bgr = False,\n",
        "                      # class_labels = LABEL_NAMES\n",
        "                      )\n",
        "  \n",
        "  #export classifier\n",
        "  tf_converter.convert(tf_model_path = classifier_graph_file,\n",
        "                      mlmodel_path = classifier_name,\n",
        "                      output_feature_names = ['cinemanet_output/Sigmoid:0'],\n",
        "                      input_name_shape_dict = {'global_average_pooling2d/Mean:0' : [1,1280]},\n",
        "                      class_labels = label_names\n",
        "                      )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etr9t8kfqBQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def export_labels(model_name_without_extension, label_names, date):\n",
        "  label_path = labels_model_path(date, model_name_without_extension)\n",
        "  text_file = open(label_path, \"w\")\n",
        "  text_file.write(\", \".join(label_names))\n",
        "  text_file.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUCpBhP7VK0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def export_model(model, model_name_without_extension, label_names, date):\n",
        "\n",
        "  export_model_keras(model, model_name_without_extension, date)\n",
        "  export_model_pb(model, model_name_without_extension, date)\n",
        "  segment_model_pb(model_name_without_extension, date)\n",
        "  convert_segment_to_coreml(model_name_without_extension, label_names, date)\n",
        "  export_labels(model_name_without_extension, label_names, date)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VS_fwdnMXndn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_exports_to_project(date):\n",
        "\n",
        "  now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "\n",
        "  !gsutil -m cp -r /tmp/{now} gs://{bucket_name}/Synopsis_Models/\n",
        "\n",
        "  # extractor_graph_file  = \"/tmp/\" + model_name_without_extension+\"_feature.pb\"\n",
        "  # classifier_graph_file  = \"/tmp/\" +  model_name_without_extension+\"_classifier.pb\"\n",
        "\n",
        "  # feature_extractor_name = model_name_without_extension + \"_feature.mlmodel\"\n",
        "  # classifier_name = model_name_without_extension + \"_classifier.mlmodel\"\n",
        "\n",
        "  # extractor_graph_file  = pb_feature_extractor_path(date, model_name_without_extension)\n",
        "  # classifier_graph_file  = pb_classifier_path(date, model_name_without_extension) \n",
        "\n",
        "  # feature_extractor_name = coreml_feature_extractor_path(date, model_name_without_extension)\n",
        "  # classifier_name = coreml_classifier_path(date, model_name_without_extension) \n",
        "\n",
        "\n",
        "  # # COPY OUR H5\n",
        "  # !gsutil -m cp -r /tmp/{model_name_without_extension}.h5 gs://{bucket_name}/Synopsis_Models/{now}/{model_name_without_extension}.h5\n",
        "  # # COPY OUR JSON AND WEIGHTS\n",
        "  # !gsutil -m cp -r /tmp/{model_name}.json gs://{bucket_name}/Synopsis_Models/{now}/{model_name}.json\n",
        "  # !gsutil -m cp -r /tmp/{model_name}-weights.h5 gs://{bucket_name}/Synopsis_Models/{now}/{model_name}-weights.h5\n",
        "  # #copy our PBs\n",
        "  # !gsutil -m cp -r /tmp/{model_name}.pb gs://{bucket_name}/Synopsis_Models/{now}/{model_name}.pb\n",
        "  # !gsutil -m cp -r {extractor_graph_file} gs://{bucket_name}/Synopsis_Models/{now}/{extractor_graph_file}\n",
        "  # !gsutil -m cp -r {classifier_graph_file} gs://{bucket_name}/Synopsis_Models/{now}/{classifier_graph_file}\n",
        "  # #copy our ML Models\n",
        "  # #!gsutil -m cp -r /tmp/{model_name}.mlmodel gs://{bucket_name}/Synopsis_Models/{model_name}.mlmodel\n",
        "  # !gsutil -m cp -r /tmp/{feature_extractor_name} gs://{bucket_name}/Synopsis_Models/{now}/{feature_extractor_name}\n",
        "  # !gsutil -m cp -r /tmp/{classifier_name} gs://{bucket_name}/Synopsis_Models/{now}/{classifier_name}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM_BI623zNgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !ls -alh /tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtxW-jnB-NLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Clean up out tmp\n",
        "# !rm -rf /tmp/Cinemanet-2019-*\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CosKeoXtRRtD",
        "colab_type": "text"
      },
      "source": [
        "## ***OUR DATA SET LOADING AND TRAINING METHOD***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEpW0VurVo7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ALL_LABELS = []\n",
        "\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "def train_on_csv_file(label_file, model_name, date, use_masked_loss = True, augmentations = None):\n",
        "  # reset all the state of tensorflow, keras an ipynb because you'll lose your mind otherwise:\n",
        "  #tf.reset_default_graph()\n",
        "  ops.reset_default_graph()\n",
        "  tf.keras.backend.set_learning_phase(1) # 0 testing, 1 training mode\n",
        "\n",
        "# preview contents of CSV to verify things are sane\n",
        "  import csv\n",
        "\n",
        "  def lenopenreadlines(filename):\n",
        "      with open(filename) as f:\n",
        "          return len(f.readlines())\n",
        "\n",
        "  def csvheaderrow(filename):\n",
        "    with open(filename) as f:\n",
        "      reader = csv.reader(f)\n",
        "      return next(reader, None)\n",
        "\n",
        "  # !head {label_file}\n",
        "\n",
        "  NUM_IMAGES = ( lenopenreadlines(label_file) - 1) # remove header\n",
        "\n",
        "  COLUMN_NAMES = csvheaderrow(label_file)\n",
        "  \n",
        "  LABEL_NAMES = COLUMN_NAMES[:]\n",
        "  LABEL_NAMES.remove(\"filepath\")\n",
        "\n",
        "  ALL_LABELS.extend(LABEL_NAMES)\n",
        "\n",
        "  # make our data set\n",
        "  BATCH_SIZE = 256\n",
        "  NUM_EPOCHS = 30\n",
        "  FILE_PATH = [\"filepath\"]\n",
        "  \n",
        "  LABELS_TO_PRINT = ' '.join(LABEL_NAMES)\n",
        "  print(\"Label contains: \" + str(NUM_IMAGES) + \" images\")\n",
        "  print(\"Label Are: \" + LABELS_TO_PRINT)\n",
        "  print(\"Creating Data Set From \" + label_file)\n",
        "\n",
        "  csv_dataset = get_dataset(label_file, BATCH_SIZE, NUM_EPOCHS, COLUMN_NAMES)\n",
        "\n",
        "  #make a new data set from our csv by mapping every value to the above function\n",
        "  split_dataset = csv_dataset.map(split_csv_to_path_and_labels)  \n",
        "\n",
        "  # make a new datas set that loads our images from the first path \n",
        "  image_and_labels_ds = split_dataset.map(load_and_preprocess_image_batch, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  # update our image floating point range to match -1, 1\n",
        "  ds = image_and_labels_ds.map(change_range)\n",
        "  \n",
        "  print(image_and_labels_ds)\n",
        "\n",
        "  model = build_model(LABEL_NAMES, use_masked_loss)\n",
        "\n",
        "  #split the final data set into train / validation splits to use for our model.\n",
        "  DATASET_SIZE = NUM_IMAGES\n",
        "\n",
        "  ds = ds.repeat()\n",
        "\n",
        "  # train_size = int(0.8 * DATASET_SIZE)\n",
        "  # val_size = int(0.1 * DATASET_SIZE)\n",
        "  # test_size = int(0.1 * DATASET_SIZE)\n",
        "\n",
        "  # print(\"train size: \" + str(train_size) + \", validation size: \" + str(val_size) + \", test_size: \" + str(test_size))\n",
        "\n",
        "  # train_dataset = ds.take(train_size)\n",
        "  # test_dataset = ds.skip(train_size)\n",
        "  # val_dataset = ds.skip(val_size)\n",
        "  # test_dataset = ds.take(test_size)\n",
        "\n",
        "  import math\n",
        "  #quick - hack to speed up training just to test our model export pipeline...\n",
        "  # steps_per_epoch = 100\n",
        "  # val_steps_per_epoch = 100\n",
        "  # epochs = 1\n",
        "  # history = model.fit(ds, epochs=epochs, steps_per_epoch=steps_per_epoch)\n",
        "\n",
        "  # steps_per_epoch =  int(math.floor(train_size/BATCH_SIZE))\n",
        "\n",
        "  # seems like we have REALLY long validation times. Some folks report issues with this on Tensorflow / Keras git.\n",
        "  # make it smaller just for now (extra / NUM_EPOCHS)\n",
        "  # val_steps_per_epoch = int(math.floor(val_size/BATCH_SIZE) / NUM_EPOCHS)\n",
        "  # val_steps_per_epoch = int(math.floor(val_size/BATCH_SIZE) / NUM_EPOCHS)\n",
        "\n",
        "  # history = model.fit(train_dataset, epochs=NUM_EPOCHS, steps_per_epoch=steps_per_epoch, validation_data=val_dataset, validation_steps=val_steps_per_epoch, validation_freq=NUM_EPOCHS)\n",
        "\n",
        "  steps_per_epoch =  int(math.floor(DATASET_SIZE/BATCH_SIZE))\n",
        "  history = model.fit(ds, epochs=NUM_EPOCHS, steps_per_epoch=steps_per_epoch)\n",
        "\n",
        "\n",
        "  print(history)\n",
        "\n",
        "  # results = model.evaluate(test_dataset)\n",
        "  # print('test loss, test acc:', results)\n",
        "  export_model(model, model_name, LABEL_NAMES, date)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "696UI0pbBD3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdhztFJQx1Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save our model to temp\n",
        "import datetime\n",
        "from google.colab import output\n",
        "\n",
        "date = datetime.datetime.now()\n",
        "now = date.strftime('%Y_%m_%d_%H_%M_%S')\n",
        "os.mkdir(\"/tmp/\" + now )\n",
        "\n",
        "\n",
        "#for label in all_label_files:\n",
        "for i in range(len(all_label_files)):\n",
        "\n",
        "  label = all_label_files[i]\n",
        "  use_masked_loss = labels_using_masked_loss[i]\n",
        "\n",
        "  label_destination = \"/tmp/Synopsis_Model_All_Concepts/\"\n",
        "  label_file =  label_destination + label\n",
        "\n",
        "  model_name =\"CinemaNet_\" + label  \n",
        "  model_name = model_name.replace(\".csv\", \"\")\n",
        "\n",
        "  print(\"!!!!!!!\")\n",
        "  print(\"!!!!!!!\")\n",
        "  print(\"!!!!!!!\")\n",
        "\n",
        "  print(\"Training Model: \" + model_name)\n",
        "\n",
        "  print(\"!!!!!!!\")\n",
        "  print(\"!!!!!!!\")\n",
        "  print(\"!!!!!!!\")\n",
        "\n",
        "  train_on_csv_file(label_file, model_name, date, use_masked_loss)\n",
        "  \n",
        "  output.clear()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dgapEs2oVIR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export to GCS once we are done with everything\n",
        "save_exports_to_project(date)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0l8IX4Wds2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ensure every filepath has a file, otherwise we may get wierd errors like so:\n",
        "# https://github.com/kratzert/finetune_alexnet_with_tensorflow/issues/30\n",
        "\n",
        "# import os\n",
        "# iterator = split_dataset.make_one_shot_iterator()\n",
        "# while True:\n",
        "#   try:\n",
        "#      filepaths, labels = iterator.get_next()\n",
        "#      list_of_filepaths = tf.unstack(filepaths)\n",
        "#      for filepath in list_of_filepaths:\n",
        "#         filepath_string = filepath.numpy().decode('UTF-8')\n",
        "#         if not os.path.isfile(filepath_string):\n",
        "#           print(filepath_string)\n",
        "\n",
        "#   except tf.errors.OutOfRangeError:\n",
        "#     break\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEYEHA_TY9au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Verify images are ok\n",
        "from PIL import Image\n",
        "\n",
        "def is_jpg_body(filename):\n",
        "    try:\n",
        "        i=Image.open(filename)\n",
        "        is_jpg = i.format =='JPEG'\n",
        "        if not is_jpg:\n",
        "          print(\"unexpected image format: \" + i.format)\n",
        "        i.close()\n",
        "        return  is_jpg\n",
        "    except IOError:\n",
        "        print(\"bad image at: \" + filename)\n",
        "        return False\n",
        "\n",
        "def is_jpg_header(filename):\n",
        "    data = open(filename,'rb').read(11)\n",
        "#    if data[:4] != '\\xff\\xd8\\xff\\xe0': \n",
        "#      print(\"Bad data at offset 4 for: \" + filename)\n",
        "#      return False\n",
        "    if data[6:] != 'JFIF\\0': \n",
        "      print(\"Bad data at offset 6 for: \" + filename)\n",
        "      return False\n",
        "    return True\n",
        "def check_tf_jpeg_decode(filename):\n",
        "  try:\n",
        "    image_contents = tf.io.read_file(filename)\n",
        "    image = tf.image.decode_jpeg(image_contents, channels=3)\n",
        "  except:\n",
        "    return False\n",
        "  \n",
        "  return True\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0572PJBfAIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lets look at some of this\n",
        "\n",
        "if tf.executing_eagerly():\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  plt.figure(figsize=(8,8)) \n",
        "  image_batch, label_batch = next(iter(image_and_labels_ds))\n",
        "  list_of_images = tf.unstack(image_batch, num=BATCH_SIZE)\n",
        "  list_of_labels = tf.unstack(label_batch, num=BATCH_SIZE)\n",
        "\n",
        "\n",
        "  print \n",
        "  for image in list_of_images:\n",
        "  # #   plt.subplot(2,2,n+1)\n",
        "    plt.imshow(image)\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnuC7TH6rIfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# predict on our model\n",
        "import os\n",
        "from urllib.parse import urlparse\n",
        "#would be smarter to batch but whatever man\n",
        "def predict_from_url(url, confidence):\n",
        "  \n",
        "  parsed_url = urlparse(url)\n",
        "\n",
        "  image_file_name = os.path.basename(parsed_url.path)\n",
        "  image = tf.keras.utils.get_file(origin=url, fname=image_file_name)\n",
        "\n",
        "  image = load_and_preprocess_single_image_from_tensor(image)\n",
        "  pred_image = image[np.newaxis,...] # dimension added to fit input size\n",
        "\n",
        "  plt.imshow(image)\n",
        "  plt.show()\n",
        "\n",
        "  prediction = model.predict(pred_image)\n",
        "  \n",
        "  prediction_dict = dict(zip(LABEL_NAMES, prediction[0]))\n",
        "\n",
        "  np.set_printoptions(precision=4)\n",
        "\n",
        "  tags = \"\"\n",
        "  for key in prediction_dict:\n",
        "    value = prediction_dict[key]\n",
        "    if value > confidence:\n",
        "      tags = tags + key + \", \"\n",
        "    \n",
        "    \n",
        "  print(tags)\n",
        "\n",
        "def predict_from_urls(urls, confidence):\n",
        "  for u in urls:\n",
        "    predict_from_url(u, confidence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSS8cme5uhcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "urls = [\"http://uratex.com.ph/uratex-blog-2015/blog/wp-content/uploads/2015/02/sofa-bed-9.jpg\",\n",
        "        \"https://i.kinja-img.com/gawker-media/image/upload/c_scale,f_auto,fl_progressive,q_80,w_800/kkgdekuiltgl8q1owmip.jpg\",\n",
        "        \"https://cdn.newsday.com/polopoly_fs/1.19213543.1528999894!/httpImage/image.jpeg_gen/derivatives/landscape_768/image.jpeg\",\n",
        "        \"https://media.tacdn.com/media/attractions-splice-spp-674x446/06/74/1a/88.jpg\",\n",
        "        \"https://pmcvariety.files.wordpress.com/2013/12/her1.jpg?w=1000\",\n",
        "        \"https://i.ytimg.com/vi/EKmT9D2VwTk/maxresdefault.jpg\",\n",
        "        \"http://essentialhome.eu/inspirations/wp-content/uploads/2018/06/Its-popcorn-time-the-greatest-movie-scenes-around-UK-4.jpg\",\n",
        "        \"https://www.theglobeandmail.com/resizer/pNJQ2snLgDH5dsZ8LCg0IWNuKI4=/2048x0/filters:quality(80)/arc-anglerfish-tgam-prod-tgam.s3.amazonaws.com/public/QX3GDBKSUZD7DJC3EBKSX4GVJQ\",\n",
        "       ]\n",
        "\n",
        "if tf.executing_eagerly():\n",
        "  predict_from_urls(urls, 0.25)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}